# Context-free languages
###### A context-free language which is not regular  
**Proposition**  
The language $\{a^nb^n |n ∈\mathbb{N}\}$ is context-free, but not regular.


**Remember Chomsky's Heirarchy**
3. Regular Grammar - recognised by *finite state automaton*
2. Context Free Grammar - recognised by *pushdown automaton*
1. Context Sensitve Grammar - recognised by *linear bounded automaton*

###### Parse trees  
**Definition**  
A parse tree for a context-free grammar is a tree labelled by terminals, non-terminals and $ε$ subject to the following rules:
1. The root is labeled $S$.
2. A vertex is a leaf iff it is labeled by a terminal or $ε$.
3. For every non-leaf $v$ there is a rule with the label of $v$ on the left, and the concatenation of the child labels on the right.

A parse tree is a graphical representation of a derivation in a context-free grammar. It shows the structure of the derivation as a tree, where each node represents a nonterminal symbol, and each leaf represents a terminal symbol or the empty string.

Here is an example of a parse tree for the string "aabb" generated by the context-free grammar $G = ({S, A, B}, {a, b}, S, P)$ where $P$ is the set of productions:

```mermaid
graph TD
  S((S))
  A((A))
  B((B))
  A1((A))
  B1((B))
  B2((b))
  
  S-->A
  S-->B
  B-->A1
  B-->B1
  B1 --> B2
```

In the parse tree, the nonterminal symbol $S$ is the root node, and it has two children representing the nonterminal symbols $A$ and $B$. The node for $A$ has a single child representing the terminal symbol $a$, while the node for $B$ has two children representing the nonterminal symbol $A$ and the terminal symbol $b$. The node for the right child of $B$ has a single child representing the terminal symbol $b$. Together, the parse tree shows the derivation $S \Rightarrow AB \Rightarrow aAb \Rightarrow aaBb \Rightarrow aabb$.


**Theorem**
The language generated by a context-free grammar consists exactly of the words built from the terminals on the leaves of finite parse trees, in order.
**Parse trees**  
To show that a word belongs to the language of a context-free grammar, try to construct a parse tree bottom-up.

**Closure properties**  
**Theorem**  
Context free languages are closed under  
1. Union  
2. Concatenation  
3. Kleene-star  
4. Intersection with regular languages

##### Non-closure properties  
**Theorem**  
Context free languages are not closed under  
1. Intersection (consider $\{a^nb^nc^m |n, m ∈\mathbb{N}\}$ and  $\{a^nb^mc^m |n, m ∈\mathbb{N}\})$  
2. Complement (consider $\{uw ||u|= |w |∧u \neq w \}$)

# Pushdown automata

##### A stack  
Reminder: A stack can be implemented by a list, where we can  
only  
1. look at the first element of the list (including testing whether there is none),  
2. remove the first element of the list,  
3. and append a new element to the front of the list.

In automata theory, a stack is a data structure used by pushdown automata (PDA) to keep track of the history of the input read so far. The stack is a last-in, first-out (LIFO) data structure that allows the PDA to remember information about previously processed input symbols and to use this information to make decisions about future input symbols.

The stack in a PDA is typically implemented as an abstract data type that supports two operations: push and pop. When the PDA reads an input symbol, it can push information onto the stack, and when it needs to make a decision about the next input symbol, it can examine the top of the stack to determine what action to take. The PDA can also pop information from the stack to backtrack to a previous state if necessary.

The use of a stack allows PDAs to recognize non-regular languages, which cannot be recognized by finite automata. By allowing the PDA to keep track of previous input symbols, the stack adds a level of memory and context to the automaton, which allows it to recognize more complex patterns in the input.

##### Pushdown automata - Informal  
- Basic idea: A pushdown automaton is a finite automaton equipped with one single stack. 
- When choosing an outgoing transition, we can take both the input symbol and the top of the stack into account.  
- Upon completing a transition, we can either push a symbol onto the stack or pop it.

###### Formal definition  
**Definition**  
A pushdown automaton over an alphabet $Σ$ is given by a tuple $(Q,Γ,δ,F)$ where  
1. $Q$ is the set of states, there is a special start state $q_0 ∈Q$, and $F ⊆Q$ is the set of final states.  
2. $Γ$ is the stack alphabet, with a special symbol $⊥ \notin Γ$ indicating that the stack is empty.  
3. $δ ⊆Q ×(Σ ∪\{ε\}) ×(Γ ∪⊥) ×Q ×(Γ ∪⊥)$ is the transition relation.

A pushdown automaton (PDA) is a type of automaton that extends the capabilities of a DFA by adding a stack. A PDA can recognize context-free languages, which cannot be recognized by a DFA. The stack in a PDA allows the automaton to keep track of the history of the input read so far, which is used to make decisions about future input symbols.

A PDA is defined by a 7-tuple $(Q, \Sigma, \Gamma, \delta, q_0, Z_0, F)$, where:

$Q$ is a finite set of states
$\Sigma$ is the input alphabet
$\Gamma$ is the stack alphabet
$\delta$ is the transition function $Q \times (\Sigma \cup {\epsilon}) \times \Gamma \rightarrow \mathcal{P}(Q \times \Gamma^*)$, where $\mathcal{P}$ denotes the power set
$q_0$ is the initial state
$Z_0$ is the initial stack symbol
$F \subseteq Q$ is the set of final states

Intuitively, a PDA works as follows: at each step, the PDA reads an input symbol from the input tape and examines the top symbol on the stack. Based on the current state, the input symbol, and the top symbol on the stack, the PDA decides which state to transition to and which symbols to push or pop from the stack. The PDA continues to read input symbols and manipulate the stack until it reaches an accepting state or a rejecting state. If the PDA reaches an accepting state, it accepts the input; otherwise, it rejects the input.

Compared to a DFA, a PDA has the added capability of using the stack to recognize context-free languages. While a DFA can only recognize regular languages, a PDA can recognize a larger class of languages that includes regular languages and context-free languages. The stack in a PDA allows it to remember information about the input read so far, which enables it to recognize patterns that a DFA cannot.

One way to understand the concept of a PDA is to think of it as a robot with a hand that can pick up and put down blocks on a stack. The blocks represent the symbols in the input alphabet and the stack alphabet, and the robot's hand represents the stack. The robot starts with an empty hand (the stack is empty) and an initial state. It then picks up the first block (reads the first input symbol) and looks at its current state and the block it is holding to determine what to do next. Depending on the current state, the input symbol, and the top block on the stack, the robot may transition to a new state, push a block onto the stack, or pop a block off the stack. It continues in this way, reading input symbols and manipulating the stack, until it reaches a final state or a rejecting state. If the robot reaches a final state, it has successfully recognized the input; otherwise, it has rejected the input.

**Links to explanations**
[Pushdown Automata (Introduction)](https://youtu.be/4ejIAmp_Atw)
[Pushdown Automata (Formal Definition)](https://youtu.be/JtRyd7Svlew)
[Pushdown Automata (Graphical Notation)](https://youtu.be/eY7fwj5jvC4)
[Pushdown Automata Example (Even Palindrome) PART-1](https://youtu.be/TEQcJybMMFU)
[Pushdown Automata Example (Even Palindrome) PART-2](https://youtu.be/BxA-aI2dyRo)
[Pushdown Automata Example (Even Palindrome) PART-3](https://youtu.be/xHj2WI1Rrl4)


###### Configurations  
**Definition**  
1. A configuration of a pushdown automaton is an element of  $Q ×Γ^∗$.  
2. The initial configuration is $(q_0,ε)$.  
3. If the current configuration is $(q,α_0α)$, the current input symbol is a and $(q,a,α_0,q′,β) ∈δ$ for $β \notin ⊥$, then a valid subsequent configuration is $(q′,βα_0α)$.  
4. If the current configuration is $(q,ε)$, the current input symbol is a and $(q,a,⊥,q′,β) ∈δ$ for $β \notin ⊥$, then a valid subsequent configuration is $(q′,β)$.
5. If the current configuration is $(q,α_0α)$, the current input symbol is a and $(q,a,α_0,q′,⊥) ∈δ$, then a valid subsequent configuration is $(q′,α)$.
6. If the current configuration is $(q,α_0α)$ and $(q,ε,α_0,q′,β) ∈δ$ for $β \notin ⊥$, then a valid subsequent configuration is $(q′,βα_0α)$ which we can reach without progressing on the input.
7. If the current configuration is $(q,ε)$ and $(q,ε,⊥,q′,β) ∈δ$ for $β \notin ⊥$, then a valid subsequent configuration is $(q′,β)$ which we can reach without progressing on the input.
8. If the current configuration is $(q,α_0α)$ and $(q,ε,α_0,q′,⊥) ∈δ$, then a valid subsequent configuration is $(q′,α)$ which we can reach without progressing on the input.
9. The accepting configurations are $(q,⊥)$ for $q ∈F$.

##### Accepting inputs  
**Definition**  
A word is accepted by a pushdown automaton if we can reach an accepting configuration upon reading it.  
**Theorem**  
A language is recognized by a pushdown automaton iff it is generated by a context-free grammar.

**Some facts on pushdown automata**  
- The requirement that the stack needs to be emptied is not used by everyone – but we DO use it in this module.
- We could push multiple symbols on the stack at the same time.  
- If we would use a queue instead of a stack, we get something more powerful (witness $\{ww |w ∈Σ^∗\}$).
- If we had two stacks, we could recognize all computably enumerable languages.
- We don’t have an analogue to the powerset construction – we can’t require our pushdown automata to be deterministic.


# Pumping Lemma for context-free languages
**Lemma**  
If $L$ is context-free, then there is some $k ∈\mathbb{N}$ such that for every $p ∈L$ with $|p|≥k$ there is a splitting $p = uvwxy$ where $|vx|≥1$ and $|vwx|≤k$ such that for all $i ∈\mathbb{N}$ it holds that $uv^iwx^iy ∈L$.

The pumping lemma for context-free languages is a tool used to prove that a given language is not context-free. It states that if a language $L$ is context-free, then there exists a constant $p > 0$ (called the pumping length) such that every string $s$ in $L$ of length $|s| \ge p$ can be written as $s = uvxyz$, where:

1.  $|vxy| \le p$
2.  $|vy| \ge 1$
3.  For all $i \ge 0$, the string $uv^ixy^iz$ is also in $L$.

In other words, for any string $s$ in $L$ of sufficient length, we can split it into five parts: $u$, $v$, $x$, $y$, and $z$, such that $v$ and $y$ can be "pumped" (repeated any number of times) without changing whether the resulting string is still in $L$.

The pumping lemma can be used to prove that a language is not context-free by assuming that it is context-free, and then showing that there exists a string in the language that cannot be pumped. If a language fails to satisfy the pumping lemma, it is not context-free.

It is important to note that the pumping lemma only provides a sufficient condition for a language to be context-free, and not a necessary one. That is, there exist context-free languages that do not satisfy the pumping lemma, and there also exist languages that are not context-free, but do satisfy the pumping lemma.


###### Pumping Lemma for context-free languages, contraposition  
Consider a language L.  
1. If for every $k ∈\mathbb{N}$ we can chose some $p ∈L$ with $|p|≥k$,
2. such that for every splitting $p = uvwxy$ such that $|vx|≥1$ and $|vwx|≤k$,
3. we can find some $i ∈\mathbb{N}$ with $uv^iwx^iy \notin L$,
4. then $L$ is not context-free.

###### First example  
We want to show that $L = \{a^nb^nc^n |n ∈\mathbb{N}\}$ is not context-free.  
1. Given the pumping length $k ∈\mathbb{N}$, we pick $a^kb^kc^k ∈L$.
2. If $a^kb^kc^k = uvwxy$ with $|vx|≥1$ and $|vwx|≤k$, we distinguish two cases:  
3. Case A: There is no $c$ in $vx$. Then $uv^0wx^0y = uwy$ has $k$-many c’s, but not also both k-many $a$’s and $b$’s. Thus, $uwy \notin L$.  
4. Case B: There is no a in vx. Then $uv^0wx^0y = uwy$ has $k$-many $a$’s, but not also both $k$-many $b$’s and $c$’s. Thus, $uwy \notin L$.  
5. Thus, L is not context-free.


